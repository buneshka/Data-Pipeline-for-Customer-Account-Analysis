{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f0e463f-8b57-46db-b367-f93baa8eb6c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "AUTHENTICATION AND DATA READING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6d999e3-d8e5-4ca4-b24a-030ec6fcdbd6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[SecretMetadata(key='ApplicationId'),\n",
       " SecretMetadata(key='directoryid'),\n",
       " SecretMetadata(key='ServiceCredential')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dbutils.secrets.listScopes()\n",
    "dbutils.secrets.list('databricks-keyvault-scope')\n",
    "#secret1=dbutils.secrets.get('databricks-keyvault-scope','ServiceCredential')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c480871a-37db-4221-9eae-e39a1a1ad1fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Mounting Azure Data Lake Storage Gen2\n",
    "\n",
    "application_id=dbutils.secrets.get('databricks-keyvault-scope','ApplicationId')\n",
    "service_credential=dbutils.secrets.get('databricks-keyvault-scope','ServiceCredential')\n",
    "directory_id=dbutils.secrets.get('databricks-keyvault-scope','directoryid')\n",
    "\n",
    "configs = {\"fs.azure.account.auth.type\": \"OAuth\",\n",
    "          \"fs.azure.account.oauth.provider.type\": \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\",\n",
    "          \"fs.azure.account.oauth2.client.id\": application_id,\n",
    "          \"fs.azure.account.oauth2.client.secret\": service_credential,\n",
    "          \"fs.azure.account.oauth2.client.endpoint\": f\"https://login.microsoftonline.com/{directory_id}/oauth2/token\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae0bf297-11ea-41a9-bcaf-86a0301a3607",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/project040datalake/project040processed has been unmounted.\nUnmounted existing mount at /mnt/project040datalake/project040processed\nMounted successfully at /mnt/project040datalake/project040processed\n"
     ]
    }
   ],
   "source": [
    "mount_point = \"/mnt/project040datalake/project040processed\"\n",
    "\n",
    "if any(mount.mountPoint == mount_point for mount in dbutils.fs.mounts()):\n",
    "    dbutils.fs.unmount(mount_point)\n",
    "    print(f\"Unmounted existing mount at {mount_point}\")\n",
    "    \n",
    "#  Optionally, you can add <directory-name> to the source URI of your mount point.\n",
    "dbutils.fs.mount(\n",
    "  source = \"abfss://project040processed@project040datalake.dfs.core.windows.net/\",\n",
    "  mount_point = mount_point,\n",
    "  extra_configs = configs)\n",
    "print(f\"Mounted successfully at {mount_point}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04f0a9af-fe60-4f76-a9da-dc36eaf3620e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted successfully at /mnt/project040datalake/project040gold\n"
     ]
    }
   ],
   "source": [
    "mount_point = \"/mnt/project040datalake/project040gold\"\n",
    "\n",
    "if any(mount.mountPoint == mount_point for mount in dbutils.fs.mounts()):\n",
    "    dbutils.fs.unmount(mount_point)\n",
    "    print(f\"Unmounted existing mount at {mount_point}\")\n",
    "    \n",
    "#  Optionally, you can add <directory-name> to the source URI of your mount point.\n",
    "dbutils.fs.mount(\n",
    "  source = \"abfss://project040gold@project040datalake.dfs.core.windows.net/\",\n",
    "  mount_point = mount_point,\n",
    "  extra_configs = configs)\n",
    "print(f\"Mounted successfully at {mount_point}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a419d53-5531-4a7b-8b75-9f10207a3627",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[MountInfo(mountPoint='/databricks-datasets', source='databricks-datasets', encryptionType=''),\n",
       " MountInfo(mountPoint='/mnt/project040datalake/project040raw', source='abfss://project040raw@project040datalake.dfs.core.windows.net/', encryptionType=''),\n",
       " MountInfo(mountPoint='/Volumes', source='UnityCatalogVolumes', encryptionType=''),\n",
       " MountInfo(mountPoint='/databricks/mlflow-tracking', source='databricks/mlflow-tracking', encryptionType=''),\n",
       " MountInfo(mountPoint='/databricks-results', source='databricks-results', encryptionType=''),\n",
       " MountInfo(mountPoint='/mnt/project040datalake/project040gold', source='abfss://project040gold@project040datalake.dfs.core.windows.net/', encryptionType=''),\n",
       " MountInfo(mountPoint='/databricks/mlflow-registry', source='databricks/mlflow-registry', encryptionType=''),\n",
       " MountInfo(mountPoint='/Volume', source='DbfsReserved', encryptionType=''),\n",
       " MountInfo(mountPoint='/volumes', source='DbfsReserved', encryptionType=''),\n",
       " MountInfo(mountPoint='/mnt/project040datalake/project040processed', source='abfss://project040processed@project040datalake.dfs.core.windows.net/', encryptionType=''),\n",
       " MountInfo(mountPoint='/', source='DatabricksRoot', encryptionType=''),\n",
       " MountInfo(mountPoint='/volume', source='DbfsReserved', encryptionType='')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbutils.fs.mounts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03d65c5d-ef08-48d5-a5b0-328d351b2eb6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+------------+-------+\n|account_id|customer_id|account_type|balance|\n+----------+-----------+------------+-------+\n|         1|         45|     Savings| 1000.5|\n|         2|         12|    Checking|2500.75|\n|         3|         78|     Savings| 1500.0|\n|         4|         34|    Checking|3000.25|\n|         5|         56|     Savings|  500.0|\n+----------+-----------+------------+-------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "accounts_df = spark.read.format(\"parquet\").load(\"/mnt/project040datalake/project040processed/silver/accounts_parquet_out/\")\n",
    "accounts_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b8cb31e-4727-42ef-beb3-d96f07620f38",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+--------------+---------+-----+------+\n|customer_id|first_name|last_name|       address|     city|state|   zip|\n+-----------+----------+---------+--------------+---------+-----+------+\n|          1|      John|      Doe|    123 Elm St|  Toronto|   ON|M4B1B3|\n|          2|      Jane|    Smith| 456 Maple Ave|   Ottawa|   ON|K1A0B1|\n|          3|   Michael|  Johnson|    789 Oak Dr| Montreal|   QC|H1A1A1|\n|          4|     Emily|    Davis|   101 Pine Rd|  Calgary|   AB|T2A0A1|\n|          5|     David|   Wilson|202 Birch Blvd|Vancouver|   BC|V5K0A1|\n+-----------+----------+---------+--------------+---------+-----+------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "customers_df = spark.read.format(\"parquet\").load(\"/mnt/project040datalake/project040processed/silver/customers_parquet_out/\")\n",
    "customers_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69b2ad74-31a2-48fb-b249-e23d36780b66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+-------------+\n|customer_id|first_name|last_name|total_balance|\n+-----------+----------+---------+-------------+\n|         44|    Amelia|   Howard|       9300.0|\n|         64|  Isabella| Gonzalez|       3200.5|\n|         12|  Isabella|      Lee|      9000.75|\n|         63| Alexander|   Foster|       425.75|\n|         53|     James|  Jenkins|       300.25|\n+-----------+----------+---------+-------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, sum\n",
    "\n",
    "# Step 1: Join accounts and customers data on customer_id\n",
    "joined_df = accounts_df.join(customers_df, on=\"customer_id\", how=\"inner\")\n",
    "\n",
    "# Step 2: Calculate the total balance for each customer\n",
    "total_balance_df = joined_df.groupBy(\"customer_id\", \"first_name\", \"last_name\") \\\n",
    "    .agg(sum(\"balance\").alias(\"total_balance\"))\n",
    "\n",
    "# Show the transformed data\n",
    "total_balance_df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "965f42fd-a7ab-4394-a316-d6759bb28b78",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Save the transformed data in the Refined (Gold) container in Parquet format\n",
    "total_balance_df.write.mode(\"overwrite\").parquet(\"/mnt/project040datalake/project040gold/total_balance/total_balance_parquet_out/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4ba0ba7-e6bc-4e18-9219-6ee236774dc2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Save the transformed data in the Refined (Gold) container in Delta format\n",
    "total_balance_df.write.format(\"delta\").mode(\"overwrite\").save(\"/mnt/project040datalake/project040gold/total_balance/delta_out/\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4473340593098745,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "Step 3: Databricks Activity (ETL_Operations_Account_Customer_Transform) Project040",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}