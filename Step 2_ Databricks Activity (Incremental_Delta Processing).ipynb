{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f0e463f-8b57-46db-b367-f93baa8eb6c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "AUTHENTICATION AND DATA READING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6d999e3-d8e5-4ca4-b24a-030ec6fcdbd6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[SecretMetadata(key='ApplicationId'),\n",
       " SecretMetadata(key='directoryid'),\n",
       " SecretMetadata(key='ServiceCredential')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dbutils.secrets.listScopes()\n",
    "dbutils.secrets.list('databricks-keyvault-scope')\n",
    "#secret1=dbutils.secrets.get('databricks-keyvault-scope','ServiceCredential')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c480871a-37db-4221-9eae-e39a1a1ad1fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Mounting Azure Data Lake Storage Gen2\n",
    "\n",
    "application_id=dbutils.secrets.get('databricks-keyvault-scope','ApplicationId')\n",
    "service_credential=dbutils.secrets.get('databricks-keyvault-scope','ServiceCredential')\n",
    "directory_id=dbutils.secrets.get('databricks-keyvault-scope','directoryid')\n",
    "\n",
    "configs = {\"fs.azure.account.auth.type\": \"OAuth\",\n",
    "          \"fs.azure.account.oauth.provider.type\": \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\",\n",
    "          \"fs.azure.account.oauth2.client.id\": application_id,\n",
    "          \"fs.azure.account.oauth2.client.secret\": service_credential,\n",
    "          \"fs.azure.account.oauth2.client.endpoint\": f\"https://login.microsoftonline.com/{directory_id}/oauth2/token\"}\n",
    "\n",
    "# Optionally, you can add <directory-name> to the source URI of your mount point.\n",
    "#dbutils.fs.mount(\n",
    "#  source = \"abfss://project040raw@project040datalake.dfs.core.windows.net/\",\n",
    "#  mount_point = \"/mnt/project040datalake/project040raw\",\n",
    "#  extra_configs = configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59565857-af13-4b67-91c4-db714bdc4568",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/project040datalake/project040raw has been unmounted.\nUnmounted existing mount at /mnt/project040datalake/project040raw\nMounted successfully at /mnt/project040datalake/project040raw\n"
     ]
    }
   ],
   "source": [
    "mount_point = \"/mnt/project040datalake/project040raw\"\n",
    "\n",
    "if any(mount.mountPoint == mount_point for mount in dbutils.fs.mounts()):\n",
    "    dbutils.fs.unmount(mount_point)\n",
    "    print(f\"Unmounted existing mount at {mount_point}\")\n",
    "    \n",
    "#  Optionally, you can add <directory-name> to the source URI of your mount point.\n",
    "dbutils.fs.mount(\n",
    "  source = \"abfss://project040raw@project040datalake.dfs.core.windows.net/\",\n",
    "  mount_point = mount_point,\n",
    "  extra_configs = configs)\n",
    "print(f\"Mounted successfully at {mount_point}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae0bf297-11ea-41a9-bcaf-86a0301a3607",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/project040datalake/project040processed has been unmounted.\nUnmounted existing mount at /mnt/project040datalake/project040processed\nMounted successfully at /mnt/project040datalake/project040processed\n"
     ]
    }
   ],
   "source": [
    "mount_point = \"/mnt/project040datalake/project040processed\"\n",
    "\n",
    "if any(mount.mountPoint == mount_point for mount in dbutils.fs.mounts()):\n",
    "    dbutils.fs.unmount(mount_point)\n",
    "    print(f\"Unmounted existing mount at {mount_point}\")\n",
    "    \n",
    "#  Optionally, you can add <directory-name> to the source URI of your mount point.\n",
    "dbutils.fs.mount(\n",
    "  source = \"abfss://project040processed@project040datalake.dfs.core.windows.net/\",\n",
    "  mount_point = mount_point,\n",
    "  extra_configs = configs)\n",
    "print(f\"Mounted successfully at {mount_point}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a419d53-5531-4a7b-8b75-9f10207a3627",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[MountInfo(mountPoint='/databricks-datasets', source='databricks-datasets', encryptionType=''),\n",
       " MountInfo(mountPoint='/mnt/project040datalake/project040raw', source='abfss://project040raw@project040datalake.dfs.core.windows.net/', encryptionType=''),\n",
       " MountInfo(mountPoint='/Volumes', source='UnityCatalogVolumes', encryptionType=''),\n",
       " MountInfo(mountPoint='/databricks/mlflow-tracking', source='databricks/mlflow-tracking', encryptionType=''),\n",
       " MountInfo(mountPoint='/databricks-results', source='databricks-results', encryptionType=''),\n",
       " MountInfo(mountPoint='/databricks/mlflow-registry', source='databricks/mlflow-registry', encryptionType=''),\n",
       " MountInfo(mountPoint='/Volume', source='DbfsReserved', encryptionType=''),\n",
       " MountInfo(mountPoint='/volumes', source='DbfsReserved', encryptionType=''),\n",
       " MountInfo(mountPoint='/mnt/project040datalake/project040processed', source='abfss://project040processed@project040datalake.dfs.core.windows.net/', encryptionType=''),\n",
       " MountInfo(mountPoint='/', source='DatabricksRoot', encryptionType=''),\n",
       " MountInfo(mountPoint='/volume', source='DbfsReserved', encryptionType='')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbutils.fs.mounts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27d5bacc-f7e4-43fb-944e-9919ced58bd0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+----------------+------------------+----------------+\n|transaction_id|account_id|transaction_date|transaction_amount|transaction_type|\n+--------------+----------+----------------+------------------+----------------+\n|             1|        45|      2024-01-01|             100.5|         Deposit|\n|             2|        12|      2024-01-02|            200.75|      Withdrawal|\n|             3|        78|      2024-01-03|             150.0|         Deposit|\n|             4|        34|      2024-01-04|            300.25|      Withdrawal|\n|             5|        56|      2024-01-05|             250.0|         Deposit|\n+--------------+----------+----------------+------------------+----------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "#read files in container\n",
    "transactions_df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"/mnt/project040datalake/project040raw/transactions.csv\")\n",
    "transactions_df.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "348c8fea-8bae-492e-b161-73a0d0a08dbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "DATA CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a39eed6-24a4-4acf-849e-4a12d7ecfc7a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+----------------+------------------+----------------+\n|transaction_id|account_id|transaction_date|transaction_amount|transaction_type|\n+--------------+----------+----------------+------------------+----------------+\n|             1|        45|      2024-01-01|             100.5|         Deposit|\n|             2|        12|      2024-01-02|            200.75|      Withdrawal|\n|             3|        78|      2024-01-03|             150.0|         Deposit|\n|             4|        34|      2024-01-04|            300.25|      Withdrawal|\n|             5|        56|      2024-01-05|             250.0|         Deposit|\n+--------------+----------+----------------+------------------+----------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType\n",
    "\n",
    "# Define schema for transactions.csv\n",
    "transactions_df_schema = StructType([\n",
    "    StructField(\"transaction_id\", IntegerType(), True),\n",
    "    StructField(\"account_id\", IntegerType(), True),\n",
    "    StructField(\"transaction_date\", StringType(), True),\n",
    "    StructField(\"transaction_amount\", FloatType(), True),\n",
    "    StructField(\"transaction_type\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Read data with custom schema\n",
    "transactions_df = spark.read.option(\"header\", \"true\").schema(transactions_df_schema).csv(\"/mnt/project040datalake/project040raw/transactions.csv\")\n",
    "transactions_df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0107d63-9546-4686-b4c0-d2490f41e996",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- transaction_id: integer (nullable = true)\n |-- account_id: integer (nullable = true)\n |-- transaction_date: string (nullable = true)\n |-- transaction_amount: float (nullable = true)\n |-- transaction_type: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "#Checking the DataFrame Schema:\n",
    "transactions_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e275683b-4a9f-4e39-8be3-ba3be4610457",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transactions count: 100\n"
     ]
    }
   ],
   "source": [
    "#Checking the DataFrame Count:\n",
    "print(\"Transactions count:\", transactions_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38bfe472-f73e-4338-8671-d68da778b223",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+----------------+------------------+----------------+\n|transaction_id|account_id|transaction_date|transaction_amount|transaction_type|\n+--------------+----------+----------------+------------------+----------------+\n|             1|        45|      2024-01-01|             100.5|         Deposit|\n|             2|        12|      2024-01-02|            200.75|      Withdrawal|\n|             3|        78|      2024-01-03|             150.0|         Deposit|\n|             4|        34|      2024-01-04|            300.25|      Withdrawal|\n|             5|        56|      2024-01-05|             250.0|         Deposit|\n+--------------+----------+----------------+------------------+----------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Drop rows where any of the critical columns have missing values\n",
    "transactions_df_cleaned = transactions_df.dropna(subset=[\"transaction_id\", \"transaction_amount\"])\n",
    "\n",
    "# Show the cleaned data\n",
    "transactions_df_cleaned.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eca43264-90dd-43df-8dc3-c777b0370fe5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+----------------+------------------+----------------+\n|transaction_id|account_id|transaction_date|transaction_amount|transaction_type|\n+--------------+----------+----------------+------------------+----------------+\n|             1|        45|      2024-01-01|             100.5|         Deposit|\n|             2|        12|      2024-01-02|            200.75|      Withdrawal|\n|             3|        78|      2024-01-03|             150.0|         Deposit|\n|             4|        34|      2024-01-04|            300.25|      Withdrawal|\n|             5|        56|      2024-01-05|             250.0|         Deposit|\n+--------------+----------+----------------+------------------+----------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values in the 'description' column with a default string 'No description'\n",
    "transactions_df_cleaned = transactions_df.fillna({\"transaction_type\": \"No transaction type\"})\n",
    "\n",
    "# Show the cleaned data\n",
    "transactions_df_cleaned.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24636b44-d80c-4e83-841d-bd464b89146e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+----------------+------------------+----------------+\n|transaction_id|account_id|transaction_date|transaction_amount|transaction_type|\n+--------------+----------+----------------+------------------+----------------+\n|            31|        71|      2024-01-31|             100.5|         Deposit|\n|            85|        65|      2024-03-25|             250.0|         Deposit|\n|            65|        69|      2024-03-05|             250.0|         Deposit|\n|            53|        86|      2024-02-22|             150.0|         Deposit|\n|            78|         4|      2024-03-18|            275.75|      Withdrawal|\n+--------------+----------+----------------+------------------+----------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicate rows based on 'transaction_id' (assuming this is the unique key)\n",
    "transactions_df_cleaned = transactions_df_cleaned.dropDuplicates([\"transaction_id\"])\n",
    "\n",
    "# Show the cleaned data\n",
    "transactions_df_cleaned.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "893b4253-ffeb-478a-9d5b-7dc8cf40253f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+----------------+------------------+----------------+\n|transaction_id|account_id|transaction_date|transaction_amount|transaction_type|\n+--------------+----------+----------------+------------------+----------------+\n+--------------+----------+----------------+------------------+----------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Filter out transactions where the amount is negative or suspiciously high\n",
    "transactions_df_cleaned1 = transactions_df_cleaned.filter((col(\"transaction_amount\") <= 0) & (col(\"transaction_amount\") >= 10000))\n",
    "\n",
    "# Show the cleaned data\n",
    "transactions_df_cleaned1.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4522c594-59be-4d93-b0a3-bc5450321f5b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+---------------+------+---------------+\n|TransactionID|AccountID|TransactionDate|Amount|TransactionType|\n+-------------+---------+---------------+------+---------------+\n|           31|       71|     2024-01-31| 100.5|        Deposit|\n|           85|       65|     2024-03-25| 250.0|        Deposit|\n|           65|       69|     2024-03-05| 250.0|        Deposit|\n|           53|       86|     2024-02-22| 150.0|        Deposit|\n|           78|        4|     2024-03-18|275.75|     Withdrawal|\n+-------------+---------+---------------+------+---------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Rename columns to standardize them\n",
    "transactions_df_cleaned = transactions_df_cleaned.withColumnRenamed(\"transaction_id\",\"TransactionID\") \\\n",
    "                                                 .withColumnRenamed(\"account_id\",\"AccountID\",)\\\n",
    "                                                 .withColumnRenamed(\"transaction_amount\",\"Amount\",) \\\n",
    "                                                 .withColumnRenamed(\"transaction_date\",\"TransactionDate\") \\\n",
    "                                                 .withColumnRenamed(\"transaction_type\",\"TransactionType\")\n",
    "                                                 \n",
    "\n",
    "# Show the cleaned data\n",
    "transactions_df_cleaned.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79367ff0-5561-4938-9ed9-d798be22bba8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+---------------+------+---------------+----+-----+---+\n|TransactionID|AccountID|TransactionDate|Amount|TransactionType|Year|Month|Day|\n+-------------+---------+---------------+------+---------------+----+-----+---+\n|           31|       71|     2024-01-31| 100.5|        Deposit|2024|    1| 31|\n|           85|       65|     2024-03-25| 250.0|        Deposit|2024|    3| 25|\n|           65|       69|     2024-03-05| 250.0|        Deposit|2024|    3|  5|\n|           53|       86|     2024-02-22| 150.0|        Deposit|2024|    2| 22|\n|           78|        4|     2024-03-18|275.75|     Withdrawal|2024|    3| 18|\n+-------------+---------+---------------+------+---------------+----+-----+---+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import year, month, day\n",
    "\n",
    "# Extract year and month from timestamp\n",
    "transactions_df_cleaned = transactions_df_cleaned.withColumn(\"Year\", year(col(\"TransactionDate\"))) \\\n",
    "                                                 .withColumn(\"Month\", month(col(\"TransactionDate\")))\\\n",
    "                                                 .withColumn(\"Day\", day(col(\"TransactionDate\")))\n",
    "\n",
    "# Show the cleaned data\n",
    "transactions_df_cleaned.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7355a9c3-6dec-41e5-982c-e20696626697",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>TransactionID</th><th>AccountID</th><th>TransactionDate</th><th>Amount</th><th>TransactionType</th><th>Year</th><th>Month</th><th>Day</th></tr></thead><tbody><tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         0,
         0,
         0,
         0,
         0,
         0,
         0,
         0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "TransactionID",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "AccountID",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "TransactionDate",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Amount",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "TransactionType",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Year",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Month",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Day",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check if there are any missing values in critical columns\n",
    "transactions_df_cleaned.select(\n",
    "    [count(when(col(c).isNull(), c)).alias(c) for c in transactions_df_cleaned.columns]\n",
    ").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4895f7b3-0d59-45c2-9778-5179c2437f48",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate transactions: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates in transaction_id\n",
    "duplicate_count = transactions_df_cleaned.groupBy(\"TransactionID\").count().filter(\"count > 1\").count()\n",
    "print(f\"Number of duplicate transactions: {duplicate_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5574c693-0b3b-4faa-a53a-bc04e89aa3a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Partition by Year,month,day and save in processed container in JSON format.\n",
    "transactions_df_cleaned.write.mode(\"overwrite\").partitionBy(\"year\",\"month\",\"day\").format(\"parquet\").save(\"/mnt/project040datalake/project040processed/transactions/accounts_json_out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5ad1400-c677-4c74-9c1d-dc9da13dec9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Partition by Year,month,day and save in processed container in JSON format.\n",
    "transactions_df_cleaned.write.mode(\"append\").partitionBy(\"year\",\"month\",\"day\").format(\"parquet\").save(\"/mnt/project040datalake/project040processed/transactions/accounts_json_out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4ea7ae5-c2eb-4c00-9ec7-0488be841b5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+---------------+------+---------------+----+-----+---+--------------------+\n|TransactionID|AccountID|TransactionDate|Amount|TransactionType|Year|Month|Day| ingestion_timestamp|\n+-------------+---------+---------------+------+---------------+----+-----+---+--------------------+\n|           31|       71|     2024-01-31| 100.5|        Deposit|2024|    1| 31|2024-11-14 22:12:...|\n|           85|       65|     2024-03-25| 250.0|        Deposit|2024|    3| 25|2024-11-14 22:12:...|\n|           65|       69|     2024-03-05| 250.0|        Deposit|2024|    3|  5|2024-11-14 22:12:...|\n|           53|       86|     2024-02-22| 150.0|        Deposit|2024|    2| 22|2024-11-14 22:12:...|\n|           78|        4|     2024-03-18|275.75|     Withdrawal|2024|    3| 18|2024-11-14 22:12:...|\n+-------------+---------+---------------+------+---------------+----+-----+---+--------------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "#add columns for ingestion time\n",
    "from pyspark.sql.functions import current_timestamp\n",
    "\n",
    "df = transactions_df_cleaned.withColumn(\"ingestion_timestamp\",current_timestamp())\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74ab0d08-5e32-43f8-bf6d-2ae9503a5173",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#DAY 01 FULL LOAD\n",
    "df.write.format(\"delta\").mode(\"overwrite\").save(\"/mnt/project040datalake/project040processed/transactions/delta/sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f866b692-cc9f-4fbf-a0a2-414037d2f714",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+---------------+------+---------------+----+-----+---+--------------------+\n|TransactionID|AccountID|TransactionDate|Amount|TransactionType|Year|Month|Day| ingestion_timestamp|\n+-------------+---------+---------------+------+---------------+----+-----+---+--------------------+\n|           31|       71|     2024-01-31| 100.5|        Deposit|2024|    1| 31|2024-11-14 22:28:...|\n|           85|       65|     2024-03-25| 250.0|        Deposit|2024|    3| 25|2024-11-14 22:28:...|\n|           65|       69|     2024-03-05| 250.0|        Deposit|2024|    3|  5|2024-11-14 22:28:...|\n|           53|       86|     2024-02-22| 150.0|        Deposit|2024|    2| 22|2024-11-14 22:28:...|\n|           78|        4|     2024-03-18|275.75|     Withdrawal|2024|    3| 18|2024-11-14 22:28:...|\n|           34|       41|     2024-02-03|300.25|     Withdrawal|2024|    2|  3|2024-11-14 22:28:...|\n|           81|       70|     2024-03-21| 100.5|        Deposit|2024|    3| 21|2024-11-14 22:28:...|\n|           28|        7|     2024-01-28|275.75|     Withdrawal|2024|    1| 28|2024-11-14 22:28:...|\n|           76|       22|     2024-03-16| 175.0|     Withdrawal|2024|    3| 16|2024-11-14 22:28:...|\n|           26|       25|     2024-01-26| 175.0|     Withdrawal|2024|    1| 26|2024-11-14 22:28:...|\n|           27|       94|     2024-01-27| 225.5|        Deposit|2024|    1| 27|2024-11-14 22:28:...|\n|           44|       13|     2024-02-13|300.25|     Withdrawal|2024|    2| 13|2024-11-14 22:28:...|\n|           12|       81|     2024-01-12|200.75|     Withdrawal|2024|    1| 12|2024-11-14 22:28:...|\n|           91|       77|     2024-03-31| 100.5|        Deposit|2024|    3| 31|2024-11-14 22:28:...|\n|           22|       37|     2024-01-22|200.75|     Withdrawal|2024|    1| 22|2024-11-14 22:28:...|\n|           93|       79|     2024-04-02| 150.0|        Deposit|2024|    4|  2|2024-11-14 22:28:...|\n|           47|       95|     2024-02-16| 225.5|        Deposit|2024|    2| 16|2024-11-14 22:28:...|\n|            1|       45|     2024-01-01| 100.5|        Deposit|2024|    1|  1|2024-11-14 22:28:...|\n|           52|       10|     2024-02-21|200.75|     Withdrawal|2024|    2| 21|2024-11-14 22:28:...|\n|           13|       29|     2024-01-13| 150.0|        Deposit|2024|    1| 13|2024-11-14 22:28:...|\n+-------------+---------+---------------+------+---------------+----+-----+---+--------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"delta\").load(\"/mnt/project040datalake/project040processed/transactions/delta/sales\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "020f6699-56ff-4706-ab04-4a98249438d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<bound method DeltaMergeBuilder.execute of <delta.tables.DeltaMergeBuilder object at 0x7fa994fa6510>>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DAY 02 - Update existing and Insert New Data based on the TransactionID.\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "existing_data = DeltaTable.forPath(spark,\"/mnt/project040datalake/project040processed/transactions/delta/sales\")\n",
    "\n",
    "existing_data.alias(\"existing\").merge(df.alias(\"new\"),\"existing.TransactionID=new.TransactionID\").whenMatchedUpdateAll().whenNotMatchedInsertAll().execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95d0a325-1d52-4443-af6e-8cccf7fe77b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+---------------+------+---------------+----+-----+---+--------------------+\n|TransactionID|AccountID|TransactionDate|Amount|TransactionType|Year|Month|Day| ingestion_timestamp|\n+-------------+---------+---------------+------+---------------+----+-----+---+--------------------+\n|           31|       71|     2024-01-31| 100.5|        Deposit|2024|    1| 31|2024-11-14 22:28:...|\n|           85|       65|     2024-03-25| 250.0|        Deposit|2024|    3| 25|2024-11-14 22:28:...|\n|           65|       69|     2024-03-05| 250.0|        Deposit|2024|    3|  5|2024-11-14 22:28:...|\n|           53|       86|     2024-02-22| 150.0|        Deposit|2024|    2| 22|2024-11-14 22:28:...|\n|           78|        4|     2024-03-18|275.75|     Withdrawal|2024|    3| 18|2024-11-14 22:28:...|\n|           34|       41|     2024-02-03|300.25|     Withdrawal|2024|    2|  3|2024-11-14 22:28:...|\n|           81|       70|     2024-03-21| 100.5|        Deposit|2024|    3| 21|2024-11-14 22:28:...|\n|           28|        7|     2024-01-28|275.75|     Withdrawal|2024|    1| 28|2024-11-14 22:28:...|\n|           76|       22|     2024-03-16| 175.0|     Withdrawal|2024|    3| 16|2024-11-14 22:28:...|\n|           26|       25|     2024-01-26| 175.0|     Withdrawal|2024|    1| 26|2024-11-14 22:28:...|\n|           27|       94|     2024-01-27| 225.5|        Deposit|2024|    1| 27|2024-11-14 22:28:...|\n|           44|       13|     2024-02-13|300.25|     Withdrawal|2024|    2| 13|2024-11-14 22:28:...|\n|           12|       81|     2024-01-12|200.75|     Withdrawal|2024|    1| 12|2024-11-14 22:28:...|\n|           91|       77|     2024-03-31| 100.5|        Deposit|2024|    3| 31|2024-11-14 22:28:...|\n|           22|       37|     2024-01-22|200.75|     Withdrawal|2024|    1| 22|2024-11-14 22:28:...|\n|           93|       79|     2024-04-02| 150.0|        Deposit|2024|    4|  2|2024-11-14 22:28:...|\n|           47|       95|     2024-02-16| 225.5|        Deposit|2024|    2| 16|2024-11-14 22:28:...|\n|            1|       45|     2024-01-01| 100.5|        Deposit|2024|    1|  1|2024-11-14 22:28:...|\n|           52|       10|     2024-02-21|200.75|     Withdrawal|2024|    2| 21|2024-11-14 22:28:...|\n|           13|       29|     2024-01-13| 150.0|        Deposit|2024|    1| 13|2024-11-14 22:28:...|\n+-------------+---------+---------------+------+---------------+----+-----+---+--------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"delta\").load(\"/mnt/project040datalake/project040processed/transactions/delta/sales\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09747e2c-40de-416f-b423-6c9b6b85d96a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#read files in container\n",
    "accounts_df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"/mnt/project040datalake/project040raw/accounts.csv\")\n",
    "customers_df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"/mnt/project040datalake/project040raw/customers.csv\")\n",
    "loan_payments_df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"/mnt/project040datalake/project040raw/loan_payments.csv\")\n",
    "loans_df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"/mnt/project040datalake/project040raw/loans.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9eac9b41-968f-4658-a25b-55f1dd270164",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "accounts_df.write.mode(\"overwrite\").parquet(\"/mnt/project040datalake/project040processed/silver/accounts_parquet_out\")\n",
    "customers_df.write.mode(\"overwrite\").parquet(\"/mnt/project040datalake/project040processed/silver/customers_parquet_out\")\n",
    "loan_payments_df.write.mode(\"overwrite\").parquet(\"/mnt/project040datalake/project040processed/silver/loan_payments_parquet_out\")\n",
    "loans_df.write.mode(\"overwrite\").parquet(\"/mnt/project040datalake/project040processed/silver/loans_parquet_out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6abdb910-f6f9-482d-8152-6506c75c9083",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Step 2: Databricks Activity (Incremental_Delta Processing)",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}